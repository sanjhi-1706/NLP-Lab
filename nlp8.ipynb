{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4TiIWNUcLjB",
        "outputId": "2500606a-5239-4a79-d262-8616add14335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Preprocessing ---\n",
            "Original: I scored 95 marks in the exam!\n",
            "Tokens: ['i', 'scored', 'NUMBER', 'marks', 'in', 'the', 'exam', 'PUNCT']\n",
            "\n",
            "Original: Visit https://example.com for more details.\n",
            "Tokens: ['visit', 'URL', 'for', 'more', 'details', 'PUNCT']\n",
            "\n",
            "Original: Numbers like 1000 or 3.14 are replaced.\n",
            "Tokens: ['numbers', 'like', 'NUMBER', 'or', 'NUMBER', 'are', 'replaced', 'PUNCT']\n",
            "\n",
            "Original: Punctuation, such as commas, should be replaced too!\n",
            "Tokens: ['punctuation', 'PUNCT', 'such', 'as', 'commas', 'PUNCT', 'should', 'be', 'replaced', 'too', 'PUNCT']\n",
            "\n",
            "\n",
            "--- Vocabulary ---\n",
            "['NUMBER', 'PUNCT', 'URL', 'are', 'as', 'be', 'commas', 'details', 'exam', 'for', 'i', 'in', 'like', 'marks', 'more', 'numbers', 'or', 'punctuation', 'replaced', 'scored', 'should', 'such', 'the', 'too', 'visit']\n",
            "\n",
            "--- TF-IDF Scores ---\n",
            "\n",
            "Sentence 1:\n",
            "NUMBER         : 0.1140\n",
            "URL            : 0.1079\n",
            "are            : 0.1079\n",
            "as             : 0.1079\n",
            "be             : 0.1079\n",
            "commas         : 0.1079\n",
            "details        : 0.1079\n",
            "exam           : 0.2045\n",
            "for            : 0.1079\n",
            "i              : 0.2045\n",
            "in             : 0.2045\n",
            "like           : 0.1079\n",
            "marks          : 0.2045\n",
            "more           : 0.1079\n",
            "numbers        : 0.1079\n",
            "or             : 0.1079\n",
            "punctuation    : 0.1079\n",
            "replaced       : 0.0602\n",
            "scored         : 0.2045\n",
            "should         : 0.1079\n",
            "such           : 0.1079\n",
            "the            : 0.2045\n",
            "too            : 0.1079\n",
            "visit          : 0.1079\n",
            "\n",
            "Sentence 2:\n",
            "NUMBER         : 0.0787\n",
            "URL            : 0.2636\n",
            "are            : 0.1412\n",
            "as             : 0.1412\n",
            "be             : 0.1412\n",
            "commas         : 0.1412\n",
            "details        : 0.2636\n",
            "exam           : 0.1412\n",
            "for            : 0.2636\n",
            "i              : 0.1412\n",
            "in             : 0.1412\n",
            "like           : 0.1412\n",
            "marks          : 0.1412\n",
            "more           : 0.2636\n",
            "numbers        : 0.1412\n",
            "or             : 0.1412\n",
            "punctuation    : 0.1412\n",
            "replaced       : 0.0787\n",
            "scored         : 0.1412\n",
            "should         : 0.1412\n",
            "such           : 0.1412\n",
            "the            : 0.1412\n",
            "too            : 0.1412\n",
            "visit          : 0.2636\n",
            "\n",
            "Sentence 3:\n",
            "NUMBER         : 0.1627\n",
            "URL            : 0.1079\n",
            "are            : 0.2045\n",
            "as             : 0.1079\n",
            "be             : 0.1079\n",
            "commas         : 0.1079\n",
            "details        : 0.1079\n",
            "exam           : 0.1079\n",
            "for            : 0.1079\n",
            "i              : 0.1079\n",
            "in             : 0.1079\n",
            "like           : 0.2045\n",
            "marks          : 0.1079\n",
            "more           : 0.1079\n",
            "numbers        : 0.2045\n",
            "or             : 0.2045\n",
            "punctuation    : 0.1079\n",
            "replaced       : 0.1140\n",
            "scored         : 0.1079\n",
            "should         : 0.1079\n",
            "such           : 0.1079\n",
            "the            : 0.1079\n",
            "too            : 0.1079\n",
            "visit          : 0.1079\n",
            "\n",
            "Sentence 4:\n",
            "NUMBER         : 0.0444\n",
            "URL            : 0.0797\n",
            "are            : 0.0797\n",
            "as             : 0.1531\n",
            "be             : 0.1531\n",
            "commas         : 0.1531\n",
            "details        : 0.0797\n",
            "exam           : 0.0797\n",
            "for            : 0.0797\n",
            "i              : 0.0797\n",
            "in             : 0.0797\n",
            "like           : 0.0797\n",
            "marks          : 0.0797\n",
            "more           : 0.0797\n",
            "numbers        : 0.0797\n",
            "or             : 0.0797\n",
            "punctuation    : 0.1531\n",
            "replaced       : 0.0853\n",
            "scored         : 0.0797\n",
            "should         : 0.1531\n",
            "such           : 0.1531\n",
            "the            : 0.0797\n",
            "too            : 0.1531\n",
            "visit          : 0.0797\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import math\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 1️⃣ Preprocessing\n",
        "# ----------------------------------------------------------\n",
        "def preprocess(sentence):\n",
        "    \"\"\"\n",
        "    Tokenize a sentence and replace:\n",
        "    - Numbers with 'NUMBER'\n",
        "    - URLs with 'URL'\n",
        "    - Punctuations with 'PUNCT'\n",
        "    - Convert to lowercase\n",
        "    \"\"\"\n",
        "    # Convert to lowercase\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # Replace URLs\n",
        "    sentence = re.sub(r'https?://\\S+|www\\.\\S+', ' URL ', sentence)\n",
        "\n",
        "    # Replace numbers\n",
        "    sentence = re.sub(r'\\b\\d+(\\.\\d+)?\\b', ' NUMBER ', sentence)\n",
        "\n",
        "    # Replace punctuations\n",
        "    sentence = re.sub(r'[^\\w\\s]', ' PUNCT ', sentence)\n",
        "\n",
        "    # Tokenize (split on whitespace)\n",
        "    tokens = sentence.split()\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 2️⃣ Term Frequency (TF)\n",
        "# ----------------------------------------------------------\n",
        "def compute_tf_with_normalization(sentence, vocab, smoothing=False):\n",
        "    \"\"\"\n",
        "    Compute normalized term frequency for one sentence.\n",
        "    TF(t,d) = log(1 + count(t,d) / total_terms)\n",
        "    If smoothing=True, add 1 to counts to handle unseen words.\n",
        "    \"\"\"\n",
        "    tokens = preprocess(sentence)\n",
        "    total_terms = len(tokens)\n",
        "    token_counts = Counter(tokens)\n",
        "\n",
        "    tf = {}\n",
        "    for term in vocab:\n",
        "        if smoothing:\n",
        "            count = token_counts.get(term, 0) + 1\n",
        "        else:\n",
        "            count = token_counts.get(term, 0)\n",
        "        # Normalized TF\n",
        "        tf[term] = math.log(1 + count / total_terms)\n",
        "\n",
        "    return tf\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 3️⃣ Inverse Document Frequency (IDF)\n",
        "# ----------------------------------------------------------\n",
        "def compute_idf(sentences, vocab, smoothing=False):\n",
        "    \"\"\"\n",
        "    Compute IDF for each term.\n",
        "    IDF(t) = log( N / df(t) )\n",
        "    If smoothing=True, use IDF(t) = log( (N + 1) / (df(t) + 1) )\n",
        "    \"\"\"\n",
        "    N = len(sentences)\n",
        "    df = defaultdict(int)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = set(preprocess(sentence))\n",
        "        for term in vocab:\n",
        "            if term in tokens:\n",
        "                df[term] += 1\n",
        "\n",
        "    idf = {}\n",
        "    for term in vocab:\n",
        "        if smoothing:\n",
        "            idf[term] = math.log((N + 1) / (df[term] + 1))\n",
        "        else:\n",
        "            if df[term] > 0:\n",
        "                idf[term] = math.log(N / df[term])\n",
        "            else:\n",
        "                idf[term] = 0.0  # unseen word case\n",
        "\n",
        "    return idf\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 4️⃣ TF-IDF computation\n",
        "# ----------------------------------------------------------\n",
        "def compute_tf_idf_scores(sentences, smoothing=False):\n",
        "    \"\"\"\n",
        "    Compute TF-IDF scores for all sentences.\n",
        "    Returns a list of dictionaries: one dict per sentence.\n",
        "    \"\"\"\n",
        "    # Build vocabulary\n",
        "    vocab = sorted(set(token for s in sentences for token in preprocess(s)))\n",
        "\n",
        "    idf = compute_idf(sentences, vocab, smoothing=smoothing)\n",
        "\n",
        "    tf_idf_all = []\n",
        "    for sentence in sentences:\n",
        "        tf = compute_tf_with_normalization(sentence, vocab, smoothing=smoothing)\n",
        "        tf_idf = {term: tf[term] * idf[term] for term in vocab}\n",
        "        tf_idf_all.append(tf_idf)\n",
        "\n",
        "    return vocab, tf_idf_all\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 5️⃣ Main function\n",
        "# ----------------------------------------------------------\n",
        "def main():\n",
        "    sentences = [\n",
        "        \"I scored 95 marks in the exam!\",\n",
        "        \"Visit https://example.com for more details.\",\n",
        "        \"Numbers like 1000 or 3.14 are replaced.\",\n",
        "        \"Punctuation, such as commas, should be replaced too!\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Preprocessing ---\")\n",
        "    for s in sentences:\n",
        "        print(f\"Original: {s}\")\n",
        "        print(f\"Tokens: {preprocess(s)}\\n\")\n",
        "\n",
        "    vocab, tfidf_scores = compute_tf_idf_scores(sentences, smoothing=True)\n",
        "\n",
        "    print(\"\\n--- Vocabulary ---\")\n",
        "    print(vocab)\n",
        "\n",
        "    print(\"\\n--- TF-IDF Scores ---\")\n",
        "    for i, sent_scores in enumerate(tfidf_scores):\n",
        "        print(f\"\\nSentence {i+1}:\")\n",
        "        for term, score in sent_scores.items():\n",
        "            if score > 0:\n",
        "                print(f\"{term:15s}: {score:.4f}\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aCCF7KLacfhO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}