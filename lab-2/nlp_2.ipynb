{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class RegexAutomaton:\n",
        "    def __init__(self, pattern):\n",
        "        self.pattern = re.compile(pattern)\n",
        "\n",
        "    def test(self, word):\n",
        "        return \"Accepted\" if self.pattern.fullmatch(word) else \"Not Accepted\"\n",
        "\n",
        "# Define regex for the DFA\n",
        "# Must start with a letter (A-Z or a-z), followed by 0 or more lowercase letters\n",
        "regex_dfa = RegexAutomaton(r\"^[a-z][a-z]*$\")\n",
        "\n",
        "# Test examples\n",
        "words = [\"Cat\", \"dog\", \"A\", \"zebra\", \"dog1\", \"1dog\", \"DogHouse\", \"Dog_house\", \" cats\"]\n",
        "\n",
        "for word in words:\n",
        "    print(f\"{word!r}: {regex_dfa.test(word.strip())}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5IjUTlFfNX-",
        "outputId": "baaf1ed0-7a9f-4d89-c55e-bd618258a9de"
      },
      "id": "F5IjUTlFfNX-",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Cat': Not Accepted\n",
            "'dog': Accepted\n",
            "'A': Not Accepted\n",
            "'zebra': Accepted\n",
            "'dog1': Not Accepted\n",
            "'1dog': Not Accepted\n",
            "'DogHouse': Not Accepted\n",
            "'Dog_house': Not Accepted\n",
            "' cats': Accepted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your function\n",
        "def simulate_dfa(word):\n",
        "    state = 'q0'\n",
        "    for char in word:\n",
        "        if state == 'q0':\n",
        "            if 'a' <= char <= 'z':\n",
        "                state = 'q1'\n",
        "            else:\n",
        "                state = 'q_dead'\n",
        "        elif state == 'q1':\n",
        "            if 'a' <= char <= 'z':\n",
        "                state = 'q1'\n",
        "            else:\n",
        "                state = 'q_dead'\n",
        "        elif state == 'q_dead':\n",
        "            return \"Not Accepted\"\n",
        "    return \"Accepted\" if state == 'q1' else \"Not Accepted\"\n",
        "\n",
        "# Test examples\n",
        "words = [\"Cat\", \"dog\", \"A\", \"zebra\", \"dog1\", \"1dog\", \"DogHouse\", \"Dog_house\", \" cats\"]\n",
        "\n",
        "for w in words:\n",
        "    print(f\"{w!r}: {simulate_dfa(w.strip())}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2Dam2FT0-42",
        "outputId": "fcf67089-6a10-4b83-aab7-ab84b480e515"
      },
      "id": "i2Dam2FT0-42",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Cat': Not Accepted\n",
            "'dog': Accepted\n",
            "'A': Not Accepted\n",
            "'zebra': Accepted\n",
            "'dog1': Not Accepted\n",
            "'1dog': Not Accepted\n",
            "'DogHouse': Not Accepted\n",
            "'Dog_house': Not Accepted\n",
            "' cats': Accepted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install automathon\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_eav6pcgvgf",
        "outputId": "d80f5e05-7462-49bb-bd7d-088c4561f946"
      },
      "id": "9_eav6pcgvgf",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting automathon\n",
            "  Downloading automathon-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting graphviz==0.16 (from automathon)\n",
            "  Downloading graphviz-0.16-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Downloading automathon-0.0.15-py3-none-any.whl (13 kB)\n",
            "Downloading graphviz-0.16-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: graphviz, automathon\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.21\n",
            "    Uninstalling graphviz-0.21:\n",
            "      Successfully uninstalled graphviz-0.21\n",
            "Successfully installed automathon-0.0.15 graphviz-0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class PluralFST:\n",
        "    def __init__(self, lexicon):\n",
        "        self.lexicon = set(word.lower() for word in lexicon)\n",
        "\n",
        "    def analyze(self, word):\n",
        "        w = word.lower()\n",
        "\n",
        "        # Singular check\n",
        "        if w in self.lexicon:\n",
        "            return f\"{w}+N+SG\"\n",
        "\n",
        "        # Rule 1: E insertion (watches, foxes, etc.)\n",
        "        if re.match(r\"^(.+?)(s|z|x|ch|sh)es$\", w):\n",
        "            base = re.sub(r\"es$\", \"\", w)\n",
        "            if base in self.lexicon:\n",
        "                return f\"{base}+N+PL\"\n",
        "\n",
        "        # Rule 2: Y replacement (tries -> try)\n",
        "        if re.match(r\"^.+ies$\", w):\n",
        "            base = re.sub(r\"ies$\", \"y\", w)\n",
        "            if base in self.lexicon:\n",
        "                return f\"{base}+N+PL\"\n",
        "\n",
        "        # Rule 3: S addition (bags -> bag)\n",
        "        if re.match(r\"^.+s$\", w):\n",
        "            base = re.sub(r\"s$\", \"\", w)\n",
        "            if base in self.lexicon:\n",
        "                return f\"{base}+N+PL\"\n",
        "\n",
        "        return \"Invalid Word\"\n",
        "\n",
        "\n",
        "# Example lexicon (replace with brown_nouns.txt contents in real use)\n",
        "lexicon = {\"fox\", \"watch\", \"try\", \"bag\", \"cat\", \"dog\", \"zebra\"}\n",
        "\n",
        "fst = PluralFST(lexicon)\n",
        "\n",
        "# Test words\n",
        "words = [\"foxes\", \"fox\", \"watch\", \"watches\", \"tries\", \"try\",\n",
        "         \"bags\", \"bag\", \"foxs\", \"cats\"]\n",
        "\n",
        "for w in words:\n",
        "    print(f\"{w!r}: {fst.analyze(w)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rVZVJZSiskv",
        "outputId": "96d70f86-e0dd-4546-fc19-59082618b9ca"
      },
      "id": "-rVZVJZSiskv",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'foxes': fox+N+PL\n",
            "'fox': fox+N+SG\n",
            "'watch': watch+N+SG\n",
            "'watches': watch+N+PL\n",
            "'tries': try+N+PL\n",
            "'try': try+N+SG\n",
            "'bags': bag+N+PL\n",
            "'bag': bag+N+SG\n",
            "'foxs': fox+N+PL\n",
            "'cats': cat+N+PL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fst_plural_analysis(word):\n",
        "    word = word.lower()\n",
        "    rev = word[::-1]  # reverse input for right-to-left processing\n",
        "\n",
        "    state = 'q0'\n",
        "    root_letters = []  # to collect root letters while reading reversed input\n",
        "\n",
        "    # Helper functions for checking endings\n",
        "    vowels = set('aeiou')\n",
        "\n",
        "    i = 0\n",
        "    n = len(rev)\n",
        "\n",
        "    while i < n:\n",
        "        c = rev[i]\n",
        "\n",
        "        if state == 'q0':\n",
        "            if c == 's':\n",
        "                state = 'q_s'  # possible plural suffix start\n",
        "                i += 1\n",
        "            elif 'a' <= c <= 'z':\n",
        "                state = 'q_copy_SG'  # singular word, start copying root\n",
        "                root_letters.append(c)\n",
        "                i += 1\n",
        "            else:\n",
        "                return \"Invalid Word\"\n",
        "\n",
        "        elif state == 'q_s':\n",
        "            if i >= n:\n",
        "                return \"Invalid Word\"  # no next letter after s\n",
        "\n",
        "            c = rev[i]\n",
        "\n",
        "            if c == 'e':\n",
        "                state = 'q_se'  # possible 'es' suffix\n",
        "                i += 1\n",
        "            elif c == 'i':\n",
        "                state = 'q_sei'  # possible 'ies' suffix\n",
        "                i += 1\n",
        "            elif c in ('x', 'z', 's', 'h'):\n",
        "                # endings that need 'es' plural, but only got 's'\n",
        "                # e.g. 'foxs' invalid\n",
        "                return \"Invalid Word\"\n",
        "            elif 'a' <= c <= 'z':\n",
        "                # regular plural ending with just s after normal root letter\n",
        "                state = 'q_copy_PL'\n",
        "                root_letters.append(c)\n",
        "                i += 1\n",
        "            else:\n",
        "                return \"Invalid Word\"\n",
        "\n",
        "        elif state == 'q_se':\n",
        "            if i >= n:\n",
        "                return \"Invalid Word\"  # incomplete suffix after se\n",
        "\n",
        "            c = rev[i]\n",
        "\n",
        "            # Check if this letter confirms valid es plural ending\n",
        "            if c in ('s', 'x', 'z', 'o'):\n",
        "                # valid es plural root ending letters\n",
        "                state = 'q_copy_PL'\n",
        "                root_letters.append(c)\n",
        "                i += 1\n",
        "            elif c == 'h':\n",
        "                # need to look further back to check ch or sh\n",
        "                if i + 1 < n:\n",
        "                    next_c = rev[i+1]\n",
        "                    if next_c == 'c' or next_c == 's':\n",
        "                        # valid ch or sh ending\n",
        "                        state = 'q_copy_PL'\n",
        "                        root_letters.append(c)\n",
        "                        root_letters.append(next_c)\n",
        "                        i += 2\n",
        "                    else:\n",
        "                        return \"Invalid Word\"\n",
        "                else:\n",
        "                    return \"Invalid Word\"\n",
        "            else:\n",
        "                return \"Invalid Word\"\n",
        "\n",
        "        elif state == 'q_sei':\n",
        "            if i >= n:\n",
        "                return \"Invalid Word\"  # incomplete ies suffix\n",
        "\n",
        "            c = rev[i]\n",
        "            if c not in vowels:\n",
        "                # consonant before ies, valid y-replacement plural\n",
        "                state = 'q_copy_PL_y'  # special copy with final 'y'\n",
        "                root_letters.append(c)\n",
        "                i += 1\n",
        "            else:\n",
        "                # vowel before ies is invalid in this simplified model\n",
        "                return \"Invalid Word\"\n",
        "\n",
        "        elif state == 'q_copy_PL':\n",
        "            # copy rest letters as root for plural\n",
        "            if i < n:\n",
        "                c = rev[i]\n",
        "                if 'a' <= c <= 'z':\n",
        "                    root_letters.append(c)\n",
        "                    i += 1\n",
        "                else:\n",
        "                    return \"Invalid Word\"\n",
        "            else:\n",
        "                # EOF reached\n",
        "                root = ''.join(root_letters[::-1])\n",
        "                return f\"{root}+N+PL\"\n",
        "\n",
        "        elif state == 'q_copy_PL_y':\n",
        "            # like q_copy_PL but final root ends with 'y' instead of 'ie'\n",
        "            if i < n:\n",
        "                c = rev[i]\n",
        "                if 'a' <= c <= 'z':\n",
        "                    root_letters.append(c)\n",
        "                    i += 1\n",
        "                else:\n",
        "                    return \"Invalid Word\"\n",
        "            else:\n",
        "                # EOF reached\n",
        "                root = ''.join(root_letters[::-1]) + 'y'\n",
        "                return f\"{root}+N+PL\"\n",
        "\n",
        "        elif state == 'q_copy_SG':\n",
        "            # copy entire word as root for singular\n",
        "            if i < n:\n",
        "                c = rev[i]\n",
        "                if 'a' <= c <= 'z':\n",
        "                    root_letters.append(c)\n",
        "                    i += 1\n",
        "                else:\n",
        "                    return \"Invalid Word\"\n",
        "            else:\n",
        "                root = ''.join(root_letters[::-1])\n",
        "                return f\"{root}+N+SG\"\n",
        "\n",
        "        else:\n",
        "            return \"Invalid Word\"\n",
        "\n",
        "    # If loop ends unexpectedly\n",
        "    if state == 'q_copy_SG':\n",
        "        root = ''.join(root_letters[::-1])\n",
        "        return f\"{root}+N+SG\"\n",
        "    else:\n",
        "        return \"Invalid Word\"\n",
        "\n",
        "\n",
        "# Example usage on brown_nouns.txt\n",
        "def process_file(input_file, output_file):\n",
        "    with open(input_file, \"r\") as f_in, open(output_file, \"w\") as f_out:\n",
        "        for line in f_in:\n",
        "            word = line.strip().lower()\n",
        "            if not word:\n",
        "                continue\n",
        "            output = fst_plural_analysis(word)\n",
        "            f_out.write(f\"{word} = {output}\\n\")\n",
        "\n",
        "\n",
        "# Run it\n",
        "process_file(\"brown_nouns.txt\", \"output2.txt\")\n",
        "print(\"Processing complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqhIuW0O3UEV",
        "outputId": "38592b0a-ca8d-405f-d42a-87be7c28bd52"
      },
      "id": "VqhIuW0O3UEV",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install automata-lib pandas graphviz colormath\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z11h90739drI",
        "outputId": "0ee975ae-38b6-4b60-cee5-65229bd5b5aa"
      },
      "id": "Z11h90739drI",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting automata-lib\n",
            "  Downloading automata_lib-9.1.2-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (0.21)\n",
            "Collecting colormath\n",
            "  Downloading colormath-3.0.0.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx>=2.6.2 in /usr/local/lib/python3.11/dist-packages (from automata-lib) (3.5)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from automata-lib) (2.4.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from automata-lib) (4.14.1)\n",
            "Collecting cached_method>=0.1.0 (from automata-lib)\n",
            "  Downloading cached_method-0.1.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading automata_lib-9.1.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cached_method-0.1.0-py3-none-any.whl (4.2 kB)\n",
            "Building wheels for collected packages: colormath\n",
            "  Building wheel for colormath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colormath: filename=colormath-3.0.0-py3-none-any.whl size=39405 sha256=6492251cd31f4f9de2f928e168688b297049e3de276e7e06a45bb54b878a1ddc\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/ce/f7/7039d7b57e1a27fc2f6bb2b2abed1be362eefece03caf2fb9a\n",
            "Successfully built colormath\n",
            "Installing collected packages: colormath, cached_method, automata-lib\n",
            "Successfully installed automata-lib-9.1.2 cached_method-0.1.0 colormath-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "def visualize_fst():\n",
        "    dot = Digraph(comment='Plural Morphology FST')\n",
        "\n",
        "    # States\n",
        "    states = ['q0', 'q_s', 'q_se', 'q_sei', 'q_copy_PL', 'q_copy_PL_y', 'q_copy_SG', 'q_dead']\n",
        "    final_states = ['q_copy_PL', 'q_copy_PL_y', 'q_copy_SG']\n",
        "\n",
        "    # Add states to graph\n",
        "    for s in states:\n",
        "        if s in final_states:\n",
        "            dot.node(s, s, shape='doublecircle')\n",
        "        elif s == 'q_dead':\n",
        "            dot.node(s, s, shape='box', style='filled', fillcolor='lightgray')\n",
        "        else:\n",
        "            dot.node(s, s)\n",
        "\n",
        "    # Transitions from q0\n",
        "    dot.edge('q0', 'q_s', label='s / ε')\n",
        "    dot.edge('q0', 'q_copy_SG', label='a–z except s / copy letter')\n",
        "\n",
        "    # Transitions from q_s\n",
        "    dot.edge('q_s', 'q_se', label='e / ε')\n",
        "    dot.edge('q_s', 'q_sei', label='i / ε')\n",
        "    dot.edge('q_s', 'q_dead', label='x,z,s,h / ε')\n",
        "    dot.edge('q_s', 'q_copy_PL', label='a–z except e,i,x,z,s,h / copy letter')\n",
        "\n",
        "    # Transitions from q_se\n",
        "    dot.edge('q_se', 'q_copy_PL', label='s,x,z,o / copy letter')\n",
        "    dot.edge('q_se', 'q_copy_PL', label='h + lookahead c or s / copy ch or sh')\n",
        "    dot.edge('q_se', 'q_dead', label='others / ε')\n",
        "\n",
        "    # Transitions from q_sei\n",
        "    dot.edge('q_sei', 'q_copy_PL_y', label='consonant / copy letter')\n",
        "    dot.edge('q_sei', 'q_dead', label='vowel / ε')\n",
        "\n",
        "    # Copy plural states transitions (loop to self)\n",
        "    dot.edge('q_copy_PL', 'q_copy_PL', label='a–z / copy letter')\n",
        "    dot.edge('q_copy_PL_y', 'q_copy_PL_y', label='a–z / copy letter')\n",
        "\n",
        "    # Copy singular state transitions (loop to self)\n",
        "    dot.edge('q_copy_SG', 'q_copy_SG', label='a–z / copy letter')\n",
        "\n",
        "    # Dead state loop\n",
        "    dot.edge('q_dead', 'q_dead', label='any / ε')\n",
        "\n",
        "    # You can add labels for final outputs on final states\n",
        "    dot.node('q_copy_PL', 'q_copy_PL\\n(final +N+PL)', shape='doublecircle', color='black')\n",
        "    dot.node('q_copy_PL_y', 'q_copy_PL_y\\n(final +N+PL)', shape='doublecircle', color='black')\n",
        "    dot.node('q_copy_SG', 'q_copy_SG\\n(final +N+SG)', shape='doublecircle', color='black')\n",
        "\n",
        "    # Render to a file (PDF/PNG/SVG)\n",
        "    dot.render('fst_plural_morphology', format='png', cleanup=True)\n",
        "    print(\"FST diagram saved as fst_plural_morphology.png\")\n",
        "\n",
        "visualize_fst()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM_6Kyd89hSz",
        "outputId": "d9f2e371-1ef6-4f6f-a487-fa942bfa06d5"
      },
      "id": "GM_6Kyd89hSz",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FST diagram saved as fst_plural_morphology.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ud9X5L7z9hQl"
      },
      "id": "ud9X5L7z9hQl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WbHDQ2MC9hOf"
      },
      "id": "WbHDQ2MC9hOf",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}